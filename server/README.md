ðŸ“– Language Model API â€“ FastAPI Backend
This is a FastAPI backend for generating text using a pretrained Transformer-based language model. The model is served via an API endpoint and takes a text context from the frontend, returning a generated string of text.

ðŸš€ Features
ðŸ§  Loads a pretrained PyTorch language model

ðŸ§¾ Accepts prompt input (context) from the frontend

ðŸ“¤ Returns generated text based on prompt

ðŸ”„ Supports CORS for easy frontend integration

ðŸ§° Requirements
Install dependencies with:

<pre> ```bash pip install -r requirements.txt ``` </pre>

ðŸ›  Setup
Ensure the following files are present:

model.pth â€“ The trained PyTorch language model

saved_vocab.pkl â€“ A pickled vocabulary (dict[int, bytes])

main.py â€“ The FastAPI server (your backend script)

ðŸ“¡ API Usage
POST /generate
Description: Generate text based on a given context.

Request:

Content-Type: application/x-www-form-urlencoded

Parameter:

context (str): Prompt to condition the language model

Example Request:

<pre> ```
curl -X POST http://localhost:8000/generate \
     -F "context=The quick brown fox"
``` </pre>
Response:

<pre> ```
{
  "generated_text": "The quick brown fox jumps over the lazy dog."
}
``` </pre>
ðŸ§ª Running Locally
Start the server with:

<pre> ```
python main.py
``` </pre>
